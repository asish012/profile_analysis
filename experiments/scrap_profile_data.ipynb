{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from bs4 import BeautifulSoup\n",
    "import os, time, random, re, json\n",
    "\n",
    "from selenium.webdriver import Chrome\n",
    "from selenium.webdriver.common.by import By\n",
    "from selenium.webdriver.common.keys import Keys\n",
    "from selenium.webdriver.support.ui import WebDriverWait\n",
    "from selenium.webdriver.support import expected_conditions as EC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # profile_url = \"../scraped_data/profile_275.html\"\n",
    "# profile_url = \"../scraped_data/profile_260.html\"\n",
    "\n",
    "# with open(profile_url) as f:\n",
    "#     soup = BeautifulSoup(f, features=\"lxml\")\n",
    "\n",
    "# # print(soup.prettify())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# soup.title.string"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# name = \"\"\n",
    "# designation = \"\" # data scientist/data analyst\n",
    "# degree = \"\" # masters/bachelors/student/...\n",
    "# degree_field = \"\" # informatic/physics/...\n",
    "# location = \"\" # munich/ny/...\n",
    "# university = \"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# profile_card = soup.find_all(\"section\", {\"class\": \"artdeco-card ember-view pv-top-card\"})\n",
    "# profile_card[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# name = profile_card[0].find(\"h1\", {\"class\": \"text-heading-xlarge inline t-24 v-align-middle break-words\"}).text.strip()\n",
    "# address = profile_card[0].find(\"span\", {\"class\": \"text-body-small inline t-black--light break-words\"}).text.strip()\n",
    "\n",
    "# print(name)\n",
    "# print(address)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Extract Experiences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_experiences(experience_tags):\n",
    "    # r_expression = r'(?<=-\\>)[0-9a-zA-Z ·-]+'\n",
    "    r_expression = r\"(?<=-\\>)[0-9,;.\\w\\s&·-]+\"\n",
    "    experience_list = []\n",
    "\n",
    "    for exp_tag in experience_tags:\n",
    "        experience_div = exp_tag.parent.parent\n",
    "        experience_div = [*experience_div.children][3]\n",
    "\n",
    "        try:\n",
    "            if experience_div.div.a is not None:\n",
    "                # Multiple job position within same company\n",
    "                multi_job = experience_div.find_all(\"div\", class_=\"display-flex align-items-center\") #.span.span\n",
    "                company = multi_job[0].span.span\n",
    "                job_title = multi_job[1].span.span\n",
    "                job_type = experience_div.find(\"span\", class_=\"t-14 t-normal\").span\n",
    "                \n",
    "                job_title = re.search(r_expression, str(job_title)).group(0)\n",
    "                company = re.search(r_expression, str(company)).group(0)\n",
    "                job_type = re.search(r_expression, str(job_type)).group(0)\n",
    "                job_type = job_type.split('·')[0] if '·' in job_type else job_type\n",
    "\n",
    "                # experience_list.append((job_title, company, *[c.strip() for c in job_type.split('·')][::-1]))\n",
    "                experience_list.append(\n",
    "                    {\n",
    "                        \"job_title\": job_title,\n",
    "                        \"company\": company,\n",
    "                        \"job_type\": job_type.split('·')[0].strip() if '·' in job_type else None,\n",
    "                        \"job_duration\": job_type.split('·')[1].strip() if '·' in job_type else job_type\n",
    "                    }\n",
    "                )\n",
    "        except Exception as e:\n",
    "            pass\n",
    "            # print(e)\n",
    "        try:\n",
    "            if experience_div.div.div.div is not None:\n",
    "                job_title = experience_div.find(\"div\", class_=\"display-flex align-items-center\").span.span\n",
    "                company = experience_div.find(\"span\", class_=\"t-14 t-normal\").span\n",
    "                duration = experience_div.find(\"span\", class_=\"t-14 t-normal t-black--light\").span\n",
    "\n",
    "                job_title = re.search(r_expression, str(job_title)).group(0)\n",
    "                company = re.search(r_expression, str(company)).group(0)\n",
    "                duration = re.search(r_expression, str(duration)).group(0)\n",
    "\n",
    "                # experience_list.append((job_title, *[c.strip() for c in company.split('·')][::-1], duration.split('·')[-1].strip()))\n",
    "                experience_list.append(\n",
    "                    {\n",
    "                        \"job_title\": job_title,\n",
    "                        \"company\": company.split('·')[0].strip() if '·' in company else company,\n",
    "                        \"job_type\": company.split('·')[1].strip() if '·' in company else None,\n",
    "                        \"job_duration\": duration.split('·')[-1].strip()\n",
    "                    }\n",
    "                )\n",
    "        except Exception as e:\n",
    "            pass\n",
    "            # print(e)\n",
    "\n",
    "    return experience_list\n",
    "\n",
    "\n",
    "##################################\n",
    "# Experiment on single profile\n",
    "##################################\n",
    "\n",
    "# profile_url = \"../scraped_data/profile_100.html\"\n",
    "\n",
    "# with open(profile_url) as f:\n",
    "#     soup = BeautifulSoup(f, features=\"lxml\")\n",
    "\n",
    "# profile_card = soup.find_all(\"section\", {\"class\": \"artdeco-card ember-view pv-top-card\"})\n",
    "\n",
    "# sections = soup.find_all(\"section\", {\"class\": \"artdeco-card ember-view break-words pb3 mt4\"})\n",
    "\n",
    "# for section in sections:\n",
    "#     experiences = section.find_all(\"a\", {\"data-field\": \"experience_company_logo\", \"class\": \"optional-action-target-wrapper display-flex\"})\n",
    "#     # print(experiences)\n",
    "#     if len(experiences):\n",
    "#         print(json.dumps(extract_experiences(experiences)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Extract other achievements"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\"profile_1.html\": {\"name\": \"Naiara W Jacoboski\", \"location\": \"Munich, Bavaria, Germany\", \"designation\": \"Data Analyst | Business Intelligence Analyst\"}, \"profile_10.html\": {\"name\": \"Sedat Karsli\", \"location\": \"Munich, Bavaria, Germany\", \"designation\": \"Senior Data Analyst\"}, \"profile_100.html\": {\"name\": \"Maximilian Pfleger\", \"location\": \"Bavaria, Germany\", \"designation\": \"Data Engineer at Pricenow | CS at TUM & EPFL | BMW Fastlane Scholar\"}, \"profile_101.html\": {\"name\": \"Daniel Ankamah, FRM\", \"location\": \"Bavaria, Germany\", \"designation\": \"Risk Data Analyst\"}, \"profile_102.html\": {\"name\": \"Amisha Agrawal\", \"location\": \"Munich, Bavaria, Germany\", \"designation\": \"Data Analyst\"}, \"profile_103.html\": {\"name\": \"Kate Asarar\", \"location\": \"Munich, Bavaria, Germany\", \"designation\": \"Data Scientist\"}, \"profile_104.html\": {\"name\": \"Marc Basten\", \"location\": \"Rosenheim, Bavaria, Germany\", \"designation\": \"BI & Data Analytics\"}, \"profile_105.html\": {\"name\": \"\\ud83c\\udfbf Oscar Huarte Belzunce\", \"location\": \"Munich, Bavaria, Germany\", \"designation\": \"Senior Product Data Analyst at AutoScout24\"}, \"profile_106.html\": {\"name\": \"Kieu Do\", \"location\": \"Greater Munich Metropolitan Area\", \"designation\": \"Data Scientist at Roche Diagnostics\"}, \"profile_107.html\": {\"name\": \"Kahina \\u00d3lafsson\", \"location\": \"Bavaria, Germany\", \"designation\": \"Neuroscientist  |  Quantitative Researcher  |  Data Scientist\"}}\n"
     ]
    }
   ],
   "source": [
    "##################################\n",
    "# Extract other achievements\n",
    "##################################\n",
    "\n",
    "\n",
    "def extract_achievements(head_section, category):\n",
    "    r_expression = r\"(?<=-\\>)[0-9,;.\\w\\s&·-]+\"\n",
    "    achievement_list = []\n",
    "\n",
    "    # if category == \"education\" or category == \"certification\":\n",
    "    achievement_tags = head_section.find_all(\"a\", class_=\"optional-action-target-wrapper display-flex flex-column full-width\")\n",
    "    achievement_tags += head_section.find_all(\"div\", class_=\"display-flex flex-column full-width\")\n",
    "    for tag in achievement_tags:\n",
    "        institute = tag.div.span.span\n",
    "        title = tag.find(\"span\", class_=\"t-14 t-normal\")\n",
    "        title = title.span if title else None\n",
    "\n",
    "        title = re.search(r_expression, str(title))\n",
    "        title = title.group(0) if title else None\n",
    "        institute = re.search(r_expression, str(institute)).group(0)\n",
    "        \n",
    "        if category == \"education\":\n",
    "            achievement_list.append(\n",
    "                {\n",
    "                    \"title\": title,\n",
    "                    \"institute\": institute\n",
    "                }\n",
    "            )\n",
    "        else:\n",
    "            # linkedin made this\n",
    "            achievement_list.append(\n",
    "                {\n",
    "                    \"title\": institute,\n",
    "                    \"institute\": title\n",
    "                }\n",
    "            )\n",
    "\n",
    "    return achievement_list\n",
    "\n",
    "\n",
    "##################################\n",
    "# Main\n",
    "##################################\n",
    "\n",
    "\n",
    "profile_data = {}\n",
    "\n",
    "for profile in os.listdir(\"../scraped_data/\")[:10]:\n",
    "    profile_data[profile] = {}\n",
    "\n",
    "    profile_url = f\"../scraped_data/{profile}\"\n",
    "    # profile_url = f\"../scraped_data/profile_100.html\"\n",
    "\n",
    "    with open(profile_url, 'r', encoding=\"utf-8\") as f:\n",
    "        soup = BeautifulSoup(f, features=\"lxml\")\n",
    "\n",
    "\n",
    "    # Extract profile info\n",
    "    profile_card = soup.find_all(\"section\", {\"class\": \"artdeco-card ember-view pv-top-card\"})[0]\n",
    "    \n",
    "    profile_data[profile][\"name\"] = profile_card.find(\"div\", class_=\"pv-text-details__left-panel\").div.h1.string.strip()\n",
    "    profile_data[profile][\"location\"] = profile_card.find(\"div\", class_=\"pb2 pv-text-details__left-panel\").span.string.strip()\n",
    "    profile_data[profile][\"designation\"] = profile_card.find(\"div\", class_=\"text-body-medium break-words\").string.strip()\n",
    "\n",
    "\n",
    "    # Extract experience and other achievements\n",
    "    sections = soup.find_all(\"section\", {\"class\": \"artdeco-card ember-view break-words pb3 mt4\"})\n",
    "\n",
    "    for section in sections:\n",
    "        # Extract experiences\n",
    "        if section.div[\"id\"] == \"experience\":\n",
    "            # print(\"found experience\")\n",
    "            experiences = section.find_all(\"a\", {\"data-field\": \"experience_company_logo\"})\n",
    "            if len(experiences):\n",
    "                profile_data[profile][\"experiences\"] = extract_experiences(experiences)\n",
    "\n",
    "        # Extract educations\n",
    "        if section.div[\"id\"] == \"education\":\n",
    "            # print(\"found education\")\n",
    "            profile_data[profile][\"educations\"] = extract_achievements(section, \"education\")\n",
    "\n",
    "        if section.div[\"id\"] == \"licenses_and_certifications\":\n",
    "            # print(\"found certifications\")\n",
    "            profile_data[profile][\"certifications\"] = extract_achievements(section, \"certification\")\n",
    "        \n",
    "        elif section.div[\"id\"] == \"courses\":\n",
    "            # print(\"found courses\")\n",
    "            profile_data[profile][\"courses\"] = extract_achievements(section, \"courses\")\n",
    "\n",
    "    # break\n",
    "\n",
    "\n",
    "print(json.dumps(profile_data))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "3c2a460bee3dcd91d90c0019b86ca24469593ce537ffd19732e7defe3509c977"
  },
  "kernelspec": {
   "display_name": "Python 3.7.13 ('ds')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
